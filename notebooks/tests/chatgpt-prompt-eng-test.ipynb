{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing OpenAI API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting Principles\n",
    "---\n",
    "* Principle 1: Write clear and specific instructions\n",
    "    * Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "        - Delimiters can be anything like: ```, \"\"\", < >, <tag> </tag>, :\n",
    "    * Tactic 2: Ask for a structured output\n",
    "        - JSON, HTML\n",
    "    * Tactic 3: Ask the model to check whether conditions are satisfied\n",
    "    * Tactic 4: \"Few-shot\" prompting\n",
    "---\n",
    "* Principle 2: Give the model time to ‚Äúthink‚Äù\n",
    "    * Tactic 1: Specify the steps required to complete a task (Ask for output in a specified format)\n",
    "    * Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion\n",
    "        - Fix instructing the model to work out its own solution first.\n",
    "---\n",
    "* Principle 3: Iterative prompt development\n",
    "---\n",
    "* AI for: summarizing, inferring, transforming, expanding, chatbots...\n",
    "\n",
    "Model Limitations: Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"\"\"\n",
    "        Genere una lista de 3 t√≠tulos de libros inventados, a lo largo,\n",
    "        con sus autores y g√©neros.\n",
    "        Proporcionelos en formato JSON con las siguientes keys:\n",
    "        book_id, t√≠tulo, autor, g√©nero.\n",
    "    \"\"\"}],\n",
    "    temperature=0, # this is the degree of randomness of the model's output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7JMVoKoGQL5w58mv4hAtXB6SJngh0 at 0x7fa6800799a0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"[\\n  {\\n    \\\"book_id\\\": 1,\\n    \\\"t\\u00edtulo\\\": \\\"El jard\\u00edn de las mariposas\\\",\\n    \\\"autor\\\": \\\"Ana Garc\\u00eda\\\",\\n    \\\"g\\u00e9nero\\\": \\\"Drama\\\"\\n  },\\n  {\\n    \\\"book_id\\\": 2,\\n    \\\"t\\u00edtulo\\\": \\\"La ciudad de los sue\\u00f1os\\\",\\n    \\\"autor\\\": \\\"Juan P\\u00e9rez\\\",\\n    \\\"g\\u00e9nero\\\": \\\"Ciencia ficci\\u00f3n\\\"\\n  },\\n  {\\n    \\\"book_id\\\": 3,\\n    \\\"t\\u00edtulo\\\": \\\"El secreto de la monta\\u00f1a\\\",\\n    \\\"autor\\\": \\\"Mar\\u00eda L\\u00f3pez\\\",\\n    \\\"g\\u00e9nero\\\": \\\"Misterio\\\"\\n  }\\n]\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1684849124,\n",
       "  \"id\": \"chatcmpl-7JMVoKoGQL5w58mv4hAtXB6SJngh0\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 140,\n",
       "    \"prompt_tokens\": 65,\n",
       "    \"total_tokens\": 205\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"book_id\": 1,\n",
      "    \"t√≠tulo\": \"El jard√≠n de las mariposas\",\n",
      "    \"autor\": \"Ana Garc√≠a\",\n",
      "    \"g√©nero\": \"Drama\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": 2,\n",
      "    \"t√≠tulo\": \"La ciudad de los sue√±os\",\n",
      "    \"autor\": \"Juan P√©rez\",\n",
      "    \"g√©nero\": \"Ciencia ficci√≥n\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": 3,\n",
      "    \"t√≠tulo\": \"El secreto de la monta√±a\",\n",
      "    \"autor\": \"Mar√≠a L√≥pez\",\n",
      "    \"g√©nero\": \"Misterio\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = '\"\"\"'\n",
    "delimiter = \"<>\"\n",
    "delimiter = \"<tag> </tag>\"\n",
    "delimiter = \":\"\n",
    "delimiter = \"```\"\n",
    "\n",
    "text = f\"\"\"\n",
    "Anthony should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "\n",
    "resumen_prompt = f\"\"\"\n",
    "# Usando el texto delimitado por {delimiter} completa la siguiente plantilla:\n",
    "\n",
    "### Resumen\n",
    "### Hechos\n",
    "- [Emoji] Puntos importantes\n",
    "\n",
    "Tu tarea es resumir el texto que te proporciono en hasta siete puntos principales y comenzar con un breve resumen.\n",
    "Elige un emoji adecuado para cada punto de lista.\n",
    "\n",
    "{delimiter}{text}{delimiter}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Resumen\n",
      "Para obtener respuestas precisas y relevantes de un modelo, es importante proporcionar instrucciones claras y espec√≠ficas.\n",
      "\n",
      "### Hechos\n",
      "- üí° Es importante proporcionar instrucciones claras y espec√≠ficas al modelo.\n",
      "- üéØ Las instrucciones claras gu√≠an al modelo hacia la salida deseada.\n",
      "- üö´ Las instrucciones vagas pueden resultar en respuestas irrelevantes o incorrectas.\n",
      "- üìù No confundas una instrucci√≥n clara con una instrucci√≥n corta.\n",
      "- üìö En muchos casos, las instrucciones m√°s largas proporcionan m√°s claridad y contexto al modelo.\n",
      "- üìà Las instrucciones m√°s largas pueden llevar a salidas m√°s detalladas y relevantes.\n",
      "- ü§ñ La calidad de las instrucciones afecta directamente la calidad de las respuestas del modelo.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(resumen_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Clear and specific instructions should be given to a model to guide it towards the desired output and reduce the chances of irrelevant or incorrect responses.\n",
      "Translation: Se deben dar instrucciones claras y espec√≠ficas a un modelo para guiarlo hacia la salida deseada y reducir las posibilidades de respuestas irrelevantes o incorrectas.\n",
      "Fable: Hab√≠a una vez dos amigos, Clara y Espec√≠fico, que viv√≠an en un bosque m√°gico. Un d√≠a, se encontraron con un modelo que no sab√≠a qu√© hacer. Clara y Espec√≠fico le dieron instrucciones claras y espec√≠ficas, y el modelo pudo hacer lo que se le ped√≠a. Desde entonces, el modelo siempre buscaba a Clara y Espec√≠fico para que le dieran instrucciones. \n",
      "Names: Clara, Espec√≠fico\n",
      "Output JSON: {\"num_names\": 2, \"spanish_summary\": \"Se deben dar instrucciones claras y espec√≠ficas a un modelo para guiarlo hacia la salida deseada y reducir las posibilidades de respuestas irrelevantes o incorrectas.\"}\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a Model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "language = \"spanish\"\n",
    "prompt_2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by \n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into {language}, invent at least two characters and then create a story like a fable for kids.\n",
    "3 - List each name in the {language} summary.\n",
    "4 - Output a json object that contains the \n",
    "  following keys: num_names, {language}_summary.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Fable: <fable>\n",
    "Names: <list of names in {language} summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "response = get_completion(prompt_2)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let x be the size of the installation in square feet.\n",
      "\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 10x\n",
      "\n",
      "Total cost: 100x + 250x + 100,000 + 10x = 360x + 100,000\n",
      "\n",
      "Is the student's solution the same as actual solution just calculated:\n",
      "No\n",
      "\n",
      "Student grade:\n",
      "Incorrect\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyC company has developed a groundbreaking AI technology that allows apes and monkeys to communicate with humans in a more advanced way than ever before. Using advanced algorithms and machine learning techniques, the AI system is able to interpret the gestures, vocalizations, and facial expressions of these primates, and translate them into human language.\n",
      "\n",
      "With this technology, researchers and caretakers can better understand the needs and emotions of these intelligent animals, and provide them with more personalized care. For example, the AI system can detect when a monkey is feeling stressed or anxious, and alert caretakers to take action to alleviate their discomfort.\n",
      "\n",
      "In addition, the AI system can also be used to teach apes and monkeys new skills and behaviors. By analyzing their movements and responses, the system can provide real-time feedback and guidance, helping these animals to learn more quickly and effectively.\n",
      "\n",
      "Overall, DyC's AI technology is revolutionizing the way we interact with apes and monkeys, and helping us to better understand and care for these amazing creatures.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Be creative:\n",
    "Tell me about Apes and monkeys AI by DyC company\n",
    "\"\"\"\n",
    "response = get_completion(prompt, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Prompt Development\n",
    "![Iterative Prompt Development](ipd.png)\n",
    "---\n",
    "* Issue 1: The text is too long \n",
    "    - Limit the number of words/sentences/characters.\n",
    "* Issue 2. Text focuses on the wrong details\n",
    "    - Ask it to focus on the aspects that are relevant to the intended audience.\n",
    "* Issue 3. Description needs a table of dimensions\n",
    "    - Ask it to extract information and organize it in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sheet_chair = \"\"\"\n",
    "OVERVIEW\n",
    "- Part of a beautiful family of mid-century inspired office furniture, \n",
    "including filing cabinets, desks, bookcases, meeting tables, and more.\n",
    "- Several options of shell color and base finishes.\n",
    "- Available with plastic back and front upholstery (SWC-100) \n",
    "or full upholstery (SWC-110) in 10 fabric and 6 leather options.\n",
    "- Base finish options are: stainless steel, matte black, \n",
    "gloss white, or chrome.\n",
    "- Chair is available with or without armrests.\n",
    "- Suitable for home or business settings.\n",
    "- Qualified for contract use.\n",
    "\n",
    "CONSTRUCTION\n",
    "- 5-wheel plastic coated aluminum base.\n",
    "- Pneumatic chair adjust for easy raise/lower action.\n",
    "\n",
    "DIMENSIONS\n",
    "- WIDTH 53 CM | 20.87‚Äù\n",
    "- DEPTH 51 CM | 20.08‚Äù\n",
    "- HEIGHT 80 CM | 31.50‚Äù\n",
    "- SEAT HEIGHT 44 CM | 17.32‚Äù\n",
    "- SEAT DEPTH 41 CM | 16.14‚Äù\n",
    "\n",
    "OPTIONS\n",
    "- Soft or hard-floor caster options.\n",
    "- Two choices of seat foam densities: \n",
    " medium (1.8 lb/ft3) or high (2.8 lb/ft3)\n",
    "- Armless or 8 position PU armrests \n",
    "\n",
    "MATERIALS\n",
    "SHELL BASE GLIDER\n",
    "- Cast Aluminum with modified nylon PA6/PA66 coating.\n",
    "- Shell thickness: 10 mm.\n",
    "SEAT\n",
    "- HD36 foam\n",
    "\n",
    "COUNTRY OF ORIGIN\n",
    "- Italy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing our stunning mid-century inspired office chair, the perfect addition to any home or business setting. Part of a beautiful family of office furniture, including filing cabinets, desks, bookcases, meeting tables, and more, this chair is available in several options of shell color and base finishes to suit your style. Choose from plastic back and front upholstery (SWC-100) or full upholstery (SWC-110) in 10 fabric and 6 leather options.\n",
      "\n",
      "The chair is constructed with a 5-wheel plastic coated aluminum base and features a pneumatic chair adjust for easy raise/lower action. It is available with or without armrests and is qualified for contract use. The base finish options are stainless steel, matte black, gloss white, or chrome.\n",
      "\n",
      "Measuring at a width of 53 cm, depth of 51 cm, and height of 80 cm, with a seat height of 44 cm and seat depth of 41 cm, this chair is designed for ultimate comfort. You can also choose between soft or hard-floor caster options and two choices of seat foam densities: medium (1.8 lb/ft3) or high (2.8 lb/ft3). The armrests are available in either an armless or 8 position PU option.\n",
      "\n",
      "The materials used in the construction of this chair are of the highest quality. The shell base glider is made of cast aluminum with modified nylon PA6/PA66 coating and has a shell thickness of 10 mm. The seat is made of HD36 foam, ensuring maximum comfort and durability.\n",
      "\n",
      "This chair is made in Italy and is the perfect combination of style and functionality. Upgrade your workspace with our mid-century inspired office chair today!\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing our mid-century inspired office chair, available in multiple shell colors and base finishes.\n",
      "Choose from plastic or full upholstery in a variety of fabrics and leathers.\n",
      "With adjustable height and optional armrests, it's perfect for home or business use.\n",
      "Made in Italy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs = \"Use at most 280 characters.\"\n",
    "specs = \"Use at most 40 words.\"\n",
    "specs = \"Use at most 3 sentences.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "{specs}\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response.replace(\". \",\".\\n\"))\n",
    "len(response.split(\" \")), len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing our mid-century inspired office chair, perfect for home or business settings.\n",
      "Available in multiple shell colors and base finishes, with plastic or full upholstery options.\n",
      "Constructed with a 5-wheel aluminum base and pneumatic chair adjust.\n",
      "Choose from soft or hard-floor casters and two seat foam densities.\n",
      "Product ID: SWC-100, SWC-110.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51, 351)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs = \"Use at most 280 characters.\"\n",
    "specs = \"Use at most 3 sentences.\"\n",
    "specs = \"Use at most 40 words.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "At the end of the description, include every 7-character \n",
    "Product ID in the technical specification.\n",
    "\n",
    "{specs}\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response.replace(\". \",\".\\n\"))\n",
    "len(response.split(\" \")), len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "<p>Introducing our mid-century inspired office chair, part of a beautiful family of furniture that includes filing cabinets, desks, bookcases, meeting tables, and more.\n",
      "This chair is available in several options of shell color and base finishes, allowing you to customize it to your liking.\n",
      "Choose between plastic back and front upholstery or full upholstery in 10 fabric and 6 leather options.\n",
      "The base finish options are stainless steel, matte black, gloss white, or chrome.\n",
      "You can also choose to have armrests or not, making it suitable for both home and business settings.\n",
      "Plus, it's qualified for contract use, ensuring its durability and longevity.</p>\n",
      "\n",
      "<p>The chair's construction is top-notch, with a 5-wheel plastic coated aluminum base and a pneumatic chair adjust for easy raise/lower action.\n",
      "You can also choose between soft or hard-floor caster options, and two choices of seat foam densities: medium (1.8 lb/ft3) or high (2.8 lb/ft3).\n",
      "The armrests are available in either an armless or 8 position PU design.</p>\n",
      "\n",
      "<p>The materials used in this chair are of the highest quality.\n",
      "The shell base glider is made of cast aluminum with modified nylon PA6/PA66 coating, with a shell thickness of 10 mm.\n",
      "The seat is made of HD36 foam, ensuring comfort and support for long periods of sitting.\n",
      "This chair is made in Italy, ensuring its quality and craftsmanship.</p>\n",
      "\n",
      "<p>Product ID: SWC-100, SWC-110</p>\n",
      "\n",
      "<table>\n",
      "  <caption>Product Dimensions</caption>\n",
      "  <tr>\n",
      "    <th>Width</th>\n",
      "    <td>53 cm | 20.87\"</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <th>Depth</th>\n",
      "    <td>51 cm | 20.08\"</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <th>Height</th>\n",
      "    <td>80 cm | 31.50\"</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <th>Seat Height</th>\n",
      "    <td>44 cm | 17.32\"</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <th>Seat Depth</th>\n",
      "    <td>41 cm | 16.14\"</td>\n",
      "  </tr>\n",
      "</table>\n",
      "</div>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(301, 1801)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs = \"Use at most 40 words.\"\n",
    "specs = \"Use at most 3 sentences.\"\n",
    "specs = \"Use at most 1500 characters.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "At the end of the description, include every 7-character \n",
    "Product ID in the technical specification.\n",
    "\n",
    "After the description, include a table that gives the \n",
    "product's dimensions. The table should have two columns.\n",
    "In the first column include the name of the dimension. \n",
    "In the second column include the measurements in inches only.\n",
    "\n",
    "Give the table the title 'Product Dimensions'.\n",
    "\n",
    "Format everything as HTML that can be used in a website. \n",
    "Place the description in a <div> element.\n",
    "\n",
    "{specs}\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response.replace(\". \",\".\\n\"))\n",
    "len(response.split(\" \")), len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<p>Introducing our mid-century inspired office chair, part of a beautiful family of furniture that includes filing cabinets, desks, bookcases, meeting tables, and more. This chair is available in several options of shell color and base finishes, allowing you to customize it to your liking. Choose between plastic back and front upholstery or full upholstery in 10 fabric and 6 leather options. The base finish options are stainless steel, matte black, gloss white, or chrome. You can also choose to have armrests or not, making it suitable for both home and business settings. Plus, it's qualified for contract use, ensuring its durability and longevity.</p>\n",
       "\n",
       "<p>The chair's construction is top-notch, with a 5-wheel plastic coated aluminum base and a pneumatic chair adjust for easy raise/lower action. You can also choose between soft or hard-floor caster options, and two choices of seat foam densities: medium (1.8 lb/ft3) or high (2.8 lb/ft3). The armrests are available in either an armless or 8 position PU design.</p>\n",
       "\n",
       "<p>The materials used in this chair are of the highest quality. The shell base glider is made of cast aluminum with modified nylon PA6/PA66 coating, with a shell thickness of 10 mm. The seat is made of HD36 foam, ensuring comfort and support for long periods of sitting. This chair is made in Italy, ensuring its quality and craftsmanship.</p>\n",
       "\n",
       "<p>Product ID: SWC-100, SWC-110</p>\n",
       "\n",
       "<table>\n",
       "  <caption>Product Dimensions</caption>\n",
       "  <tr>\n",
       "    <th>Width</th>\n",
       "    <td>53 cm | 20.87\"</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>Depth</th>\n",
       "    <td>51 cm | 20.08\"</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>Height</th>\n",
       "    <td>80 cm | 31.50\"</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>Seat Height</th>\n",
       "    <td>44 cm | 17.32\"</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>Seat Depth</th>\n",
       "    <td>41 cm | 16.14\"</td>\n",
       "  </tr>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing\n",
    "---\n",
    "* Summarize with a word/sentence/character limit\n",
    "* Summarize with a focus on shipping and delivery\n",
    "* Summarize with a focus on price and value\n",
    "    - Summaries include topics that are not related to the topic of focus.\n",
    "* Try \"extract\" instead of \"summarize\"\n",
    "* Summarize multiple product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_review = \"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\ \n",
    "super cute, and its face has a friendly look. It's \\ \n",
    "a bit small for what I paid though. I think there \\ \n",
    "might be other options that are bigger for the \\ \n",
    "same price. It arrived a day earlier than expected, \\ \n",
    "so I got to play with it myself before I gave it \\ \n",
    "to her.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product arrived a day early, but customer felt it was a bit small for the price paid. However, daughter loves the soft and cute panda plush toy.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an e-commerce site to give feedback to the \\\n",
    "Shipping department. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words, and focusing on any aspects \\\n",
    "that mention shipping, delivery, price and perceived value of the product. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Panda Plush Toy\n",
      "1-Topic: Appearance\n",
      "1-Summary: Soft and super cute with a friendly face.\n",
      "2-Topic: Size\n",
      "2-Summary: A bit small for the price paid.\n",
      "3-Topic: Price\n",
      "3-Summary: Expensive for the size.\n",
      "4-Topic: Shipping\n",
      "4-Summary: Arrived a day earlier than expected.\n",
      "5-Topic: Usage\n",
      "5-Summary: Perfect for kids who love plush toys.\n",
      "6-Topic: Durability\n",
      "6-Summary: No comment on durability.\n",
      "7-Topic: Material\n",
      "7-Summary: No comment on material.\n",
      "8-Topic: Customer type\n",
      "8-Summary: Ideal for kids.\n",
      "9-Topic: Satisfaction\n",
      "9-Summary: Daughter loves it and takes it everywhere.\n",
      "10-Topic: Alternatives\n",
      "10-Summary: Other options might be bigger for the same price.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a serie of short summaries from a product \\\n",
    "review from an e-commerce site. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. Divide the summary in topics, at least 10 topics, if you do not find any other topic let empty.\n",
    "\n",
    "Use the following format:\n",
    "## Product name\n",
    "1-Topic: [text]\n",
    "1-Summary: [text]\n",
    "2-Topic: [text]\n",
    "2-Summary: [text]\n",
    "...\n",
    "N-Topic: [text]\n",
    "N-Summary: [text]\n",
    "\n",
    "Ex. \n",
    "i-Topic: Client Satisfaction or Customer type or Appearance or Size or Shipping or Delivery or Price or Usage or ...\n",
    "i-Summary: ...\n",
    "...\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shipping: Arrived a day earlier than expected. \n",
      "Delivery: N/A \n",
      "Price: A bit small for what I paid. \n",
      "Perceived value: Other options might be bigger for the same price.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 28)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to extract relevant information from \\ \n",
    "a product review from an e-commerce site to give \\\n",
    "feedback to the Shipping department. \n",
    "\n",
    "From the review below, delimited by triple quotes \\\n",
    "extract the information relevant to shipping, \\ \n",
    "delivery, price and perceived value. Limit to 20 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response), len(response.split(' '))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring\n",
    "---\n",
    "* Sentiment (positive/negative)\n",
    "* Identify types of emotions\n",
    "* Identify anger\n",
    "* Extract product and company name from customer reviews\n",
    "* Doing multiple tasks at once\n",
    "* Inferring topics\n",
    "    - Infer 5 topics\n",
    "    - Make a news alert for certain topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Review text: '''{lamp_review}'''\n",
    "\n",
    "Solve all items below:\n",
    "\n",
    "1. \n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "2.\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "3.\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "4.\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "5.\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "6.\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. happy, satisfied, grateful, impressed, content\n",
      "2. positive\n",
      "3. happy, grateful, impressed, satisfied, relieved\n",
      "4. no\n",
      "5. {\"Item\": \"lamp\", \"Brand\": \"Lumina\"}\n",
      "6. {\"Sentiment\": \"positive\", \"Anger\": false, \"Item\": \"lamp\", \"Brand\": \"Lumina\"}\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the government, \n",
    "public sector employees were asked to rate their level \n",
    "of satisfaction with the department they work at. \n",
    "The results revealed that NASA was the most popular \n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings, \n",
    "stating, \"I'm not surprised that NASA came out on top. \n",
    "It's a great place to work with amazing people and \n",
    "incredible opportunities. I'm proud to be a part of \n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team, \n",
    "with Director Tom Johnson stating, \"We are thrilled to \n",
    "hear that our employees are satisfied with their work at NASA. \n",
    "We have a talented and dedicated team who work tirelessly \n",
    "to achieve our goals, and it's fantastic to see that their \n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the \n",
    "Social Security Administration had the lowest satisfaction \n",
    "rating, with only 45% of employees indicating they were \n",
    "satisfied with their job. The government has pledged to \n",
    "address the concerns raised by employees in the survey and \n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Review text: '''{story}'''\n",
    "\n",
    "Solve all items below:\n",
    "\n",
    "1. \n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "2.\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "3.\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "4.\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "5.\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "6.\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. proud, thrilled, concerned\n",
      "2. positive\n",
      "3. satisfied, talented, dedicated\n",
      "4. no\n",
      "5. {\"Item\": \"unknown\", \"Brand\": \"NASA\"}\n",
      "6. {\"Sentiment\": \"positive\", \"Anger\": false, \"Item\": \"unknown\", \"Brand\": \"NASA\"}\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government survey, job satisfaction, NASA, Social Security Administration, employee concerns\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['government survey',\n",
       " 'job satisfaction',\n",
       " 'nasa',\n",
       " 'social security administration',\n",
       " 'employee concerns']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_list = response.lower().split(sep=',')\n",
    "topic_list = list(map(lambda x: x.strip(), topic_list))\n",
    "topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- government survey: 1\n",
      "- job satisfaction: 1\n",
      "- nasa: 1\n",
      "- social security administration: 1\n",
      "- employee concerns: 1\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic.\\\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming\n",
    "- language translation\n",
    "    - universal\n",
    "    - tone adjustment\n",
    "- format conversion (\"translation\")\n",
    "    - json, html\n",
    "- spelling and grammar checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_messages = [\n",
    "  \"La performance du syst√®me est plus lente que d'habitude.\",  # System performance is slower than normal         \n",
    "  \"Mi monitor tiene p√≠xeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
    "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
    "  \"M√≥j klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
    "  \"ÊàëÁöÑÂ±èÂπïÂú®Èó™ÁÉÅ\"                                               # My screen is flashing\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message (This is French.): La performance du syst√®me est plus lente que d'habitude.\n",
      "English: The system performance is slower than usual.\n",
      "Korean: ÏãúÏä§ÌÖú ÏÑ±Îä•Ïù¥ ÌèâÏÜåÎ≥¥Îã§ ÎäêÎ¶ΩÎãàÎã§. \n",
      "\n",
      "Original message (This is Spanish.): Mi monitor tiene p√≠xeles que no se iluminan.\n",
      "English: My monitor has pixels that don't light up.\n",
      "Korean: ÎÇ¥ Î™®ÎãàÌÑ∞ÏóêÎäî Î∂àÏù¥ ÏºúÏßÄÏßÄ ÏïäÎäî ÌîΩÏÖÄÏù¥ ÏûàÏäµÎãàÎã§. \n",
      "\n",
      "Original message (This is Italian.): Il mio mouse non funziona\n",
      "English: My mouse is not working.\n",
      "Korean: ÎÇ¥ ÎßàÏö∞Ïä§Í∞Ä ÏûëÎèôÌïòÏßÄ ÏïäÏäµÎãàÎã§. \n",
      "\n",
      "Original message (This is Polish.): M√≥j klawisz Ctrl jest zepsuty\n",
      "English: My Ctrl key is broken.\n",
      "Korean: Ï†ú Ctrl ÌÇ§Í∞Ä Í≥†Ïû• ÎÇ¨Ïñ¥Ïöî. \n",
      "\n",
      "Original message (This is Chinese (Simplified).): ÊàëÁöÑÂ±èÂπïÂú®Èó™ÁÉÅ\n",
      "English: My screen is flickering.\n",
      "Korean: ÎÇ¥ ÌôîÎ©¥Ïù¥ ÍπúÎπ°ÏûÖÎãàÎã§. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for issue in user_messages:\n",
    "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
    "    lang = get_completion(prompt)\n",
    "    print(f\"Original message ({lang}): {issue}\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Translate the following  text to English \\\n",
    "    and Korean: ```{issue}```\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response, \"\\n\")\n",
    "    time.sleep(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two sets of text are not equivalent as they are translations of the same original messages in different languages. The translations are different in each language, but they convey the same meaning as the original messages. The differences are in the choice of words and grammar structures used in each language.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Original message (This is French.): La performance du syst√®me est plus lente que d'habitude.\n",
    "English: The system performance is slower than usual.\n",
    "Korean: ÏãúÏä§ÌÖú ÏÑ±Îä•Ïù¥ ÌèâÏÜåÎ≥¥Îã§ ÎäêÎ¶ΩÎãàÎã§. \n",
    "\n",
    "Original message (This is Spanish.): Mi monitor tiene p√≠xeles que no se iluminan.\n",
    "English: My monitor has pixels that don't light up.\n",
    "Korean: ÎÇ¥ Î™®ÎãàÌÑ∞ÏóêÎäî Î∂àÏù¥ ÏºúÏßÄÏßÄ ÏïäÎäî ÌîΩÏÖÄÏù¥ ÏûàÏäµÎãàÎã§. \n",
    "\n",
    "Original message (This is Italian.): Il mio mouse non funziona\n",
    "English: My mouse is not working.\n",
    "Korean: ÎÇ¥ ÎßàÏö∞Ïä§Í∞Ä ÏûëÎèôÌïòÏßÄ ÏïäÏäµÎãàÎã§. \n",
    "\n",
    "Original message (This is Polish.): M√≥j klawisz Ctrl jest zepsuty\n",
    "English: My Ctrl key is broken.\n",
    "Korean: Ï†ú Ctrl ÌÇ§Í∞Ä Í≥†Ïû• ÎÇ¨Ïñ¥Ïöî. \n",
    "\n",
    "Original message (This is Chinese (Simplified).): ÊàëÁöÑÂ±èÂπïÂú®Èó™ÁÉÅ\n",
    "English: My screen is flickering.\n",
    "Korean: ÎÇ¥ ÌôîÎ©¥Ïù¥ ÍπúÎπ°ÏûÖÎãàÎã§. \n",
    "\n",
    "_____\n",
    "\n",
    "Original message (French): La performance du syst√®me est plus lente que d'habitude.\n",
    "Translated message (English): The system performance is slower than usual.\n",
    "Translated message (Korean): ÏãúÏä§ÌÖú ÏÑ±Îä•Ïù¥ ÌèâÏÜåÎ≥¥Îã§ ÎäêÎ¶ΩÎãàÎã§.\n",
    "\n",
    "Original message (Spanish): Mi monitor tiene p√≠xeles que no se iluminan.\n",
    "Translated message (English): My monitor has pixels that are not lighting.\n",
    "Translated message (Korean): ÎÇ¥ Î™®ÎãàÌÑ∞ÏóêÎäî Ï°∞Î™ÖÏù¥ ÎêòÏßÄ ÏïäÎäî ÌîΩÏÖÄÏù¥ ÏûàÏäµÎãàÎã§.\n",
    "\n",
    "Original message (Italian): Il mio mouse non funziona.\n",
    "Translated message (English): My mouse is not working.\n",
    "Translated message (Korean): ÎÇ¥ ÎßàÏö∞Ïä§Í∞Ä ÏûëÎèôÌïòÏßÄ ÏïäÏäµÎãàÎã§.\n",
    "\n",
    "Original message (Polish): M√≥j klawisz Ctrl jest zepsuty.\n",
    "Translated message (English): My keyboard has a broken control key.\n",
    "Translated message (Korean): ÎÇ¥ ÌÇ§Î≥¥ÎìúÏùò Ïª®Ìä∏Î°§ ÌÇ§Í∞Ä Í≥†Ïû• ÎÇ¨ÏäµÎãàÎã§.\n",
    "\n",
    "Original message (Chinese): ÊàëÁöÑÂ±èÂπïÂú®Èó™ÁÉÅ\n",
    "Translated message (English): My screen is flashing.\n",
    "Translated message (Korean): ÎÇ¥ ÌôîÎ©¥Ïù¥ ÍπúÎπ°ÏûÖÎãàÎã§.\n",
    "\n",
    "_____\n",
    "\n",
    "are both text equivalent?\n",
    "highlight the differences!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ```Hola, me gustar√≠a ordenar una licuadora```\n",
      "2. French\n",
      "3. French: ```Je voudrais commander un ballon de basket```\n",
      "   Spanish: ```Quiero ordenar una pelota de baloncesto```\n",
      "   English Pirate: ```Arrr, I be wantin' to order a basketball```\n",
      "4. Original message (French): La performance du syst√®me est plus lente que d'habitude.\n",
      "   Translated message (English): The system performance is slower than usual.\n",
      "   Translated message (Korean): ÏãúÏä§ÌÖú ÏÑ±Îä•Ïù¥ ÌèâÏÜåÎ≥¥Îã§ ÎäêÎ¶ΩÎãàÎã§.\n",
      "\n",
      "   Original message (Spanish): Mi monitor tiene p√≠xeles que no se iluminan.\n",
      "   Translated message (English): My monitor has pixels that are not lighting.\n",
      "   Translated message (Korean): ÎÇ¥ Î™®ÎãàÌÑ∞ÏóêÎäî Ï°∞Î™ÖÏù¥ ÎêòÏßÄ ÏïäÎäî ÌîΩÏÖÄÏù¥ ÏûàÏäµÎãàÎã§.\n",
      "\n",
      "   Original message (Italian): Il mio mouse non funziona.\n",
      "   Translated message (English): My mouse is not working.\n",
      "   Translated message (Korean): ÎÇ¥ ÎßàÏö∞Ïä§Í∞Ä ÏûëÎèôÌïòÏßÄ ÏïäÏäµÎãàÎã§.\n",
      "\n",
      "   Original message (Polish): M√≥j klawisz Ctrl jest zepsuty.\n",
      "   Translated message (English): My keyboard has a broken control key.\n",
      "   Translated message (Korean): ÎÇ¥ ÌÇ§Î≥¥ÎìúÏùò Ïª®Ìä∏Î°§ ÌÇ§Í∞Ä Í≥†Ïû• ÎÇ¨ÏäµÎãàÎã§.\n",
      "\n",
      "   Original message (Chinese): ÊàëÁöÑÂ±èÂπïÂú®Èó™ÁÉÅ\n",
      "   Translated message (English): My screen is flashing.\n",
      "   Translated message (Korean): ÎÇ¥ ÌôîÎ©¥Ïù¥ ÍπúÎπ°ÏûÖÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "1.\n",
    "Translate the following English text to Spanish: \\ \n",
    "```Hi, I would like to order a blender```\n",
    "\n",
    "2.\n",
    "Tell me which language this is: \n",
    "```Combien co√ªte le lampadaire?```\n",
    "\n",
    "3.\n",
    "Translate the following  text to French and Spanish\n",
    "and English pirate: \\\n",
    "```I want to order a basketball```\n",
    "\n",
    "4.\n",
    "user_messages = [\n",
    "  \"La performance du syst√®me est plus lente que d'habitude.\",  # System performance is slower than normal         \n",
    "  \"Mi monitor tiene p√≠xeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
    "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
    "  \"M√≥j klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
    "  \"ÊàëÁöÑÂ±èÂπïÂú®Èó™ÁÉÅ\"                                               # My screen is flashing\n",
    "] \n",
    "\n",
    "for issue in user_messages:\n",
    "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
    "    lang = get_completion(prompt)\n",
    "    print(f\"Original message ({lang}): {issue}\")\n",
    "\n",
    "    prompt = f'''\n",
    "    Translate the following  text to English \\\n",
    "    and Korean: ```{issue}```\n",
    "    '''\n",
    "    response = get_completion(prompt)\n",
    "    print(response, \"\\n\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got this for my daughter's birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. However, one of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. Additionally, it's a bit small for what I paid for it. I think there might be other options that are bigger for the same price. On the positive side, it arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "Got this for my daughter for her birthday cuz she keeps taking \\\n",
    "mine from my room.  Yes, adults also like pandas too.  She takes \\\n",
    "it everywhere with her, and it's super soft and cute.  One of the \\\n",
    "ears is a bit lower than the other, and I don't think that was \\\n",
    "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
    "though. I think there might be other options that are bigger for \\\n",
    "the same price.  It arrived a day earlier than expected, so I got \\\n",
    "to play with it myself before I gave it to my daughter.\n",
    "\"\"\"\n",
    "prompt = f\"proofread and correct this review: ```{text}```\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install redlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:red;font-weight:700;text-decoration:line-through;\">Got </span><span style=\"color:red;font-weight:700;\">I got </span>this for my <span style=\"color:red;font-weight:700;text-decoration:line-through;\">daughter for her </span><span style=\"color:red;font-weight:700;\">daughter's </span>birthday <span style=\"color:red;font-weight:700;text-decoration:line-through;\">cuz </span><span style=\"color:red;font-weight:700;\">because </span>she keeps taking mine from my <span style=\"color:red;font-weight:700;text-decoration:line-through;\">room.  </span><span style=\"color:red;font-weight:700;\">room. </span>Yes, adults also like pandas <span style=\"color:red;font-weight:700;text-decoration:line-through;\">too.  </span><span style=\"color:red;font-weight:700;\">too. </span>She takes it everywhere with her, and it's super soft and <span style=\"color:red;font-weight:700;text-decoration:line-through;\">cute.  One </span><span style=\"color:red;font-weight:700;\">cute. However, one </span>of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. <span style=\"color:red;font-weight:700;text-decoration:line-through;\">It's </span><span style=\"color:red;font-weight:700;\">Additionally, it's </span>a bit small for what I paid for <span style=\"color:red;font-weight:700;text-decoration:line-through;\">it though. </span><span style=\"color:red;font-weight:700;\">it. </span>I think there might be other options that are bigger for the same <span style=\"color:red;font-weight:700;text-decoration:line-through;\">price.  It </span><span style=\"color:red;font-weight:700;\">price. On the positive side, it </span>arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from redlines import Redlines\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "diff = Redlines(text,response)\n",
    "display(HTML(diff.output_markdown))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding\n",
    "- Customize the automated replies (customer email)\n",
    "- Remind the model to use details from the customer's email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the sentiment from the lesson on \"inferring\",\n",
    "# and the original customer message, customize the email\n",
    "sentiment = \"negative\"\n",
    "\n",
    "# review for a blender\n",
    "review = f\"\"\"\n",
    "So, they still had the 17 piece system on seasonal \\\n",
    "sale for around $49 in the month of November, about \\\n",
    "half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went \\\n",
    "up to about anywhere from between $70-$89 for the same \\\n",
    "system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. \\\n",
    "So it looks okay, but if you look at the base, the part \\\n",
    "where the blade locks into place doesn‚Äôt look as good \\\n",
    "as in previous editions from a few years ago, but I \\\n",
    "plan to be very gentle with it (example, I crush \\\n",
    "very hard items like beans, ice, rice, etc. in the \\ \n",
    "blender first then pulverize them in the serving size \\\n",
    "I want in the blender then switch to the whipping \\\n",
    "blade for a finer flour, and use the cross cutting blade \\\n",
    "first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making \\\n",
    "smoothies, finely cut and freeze the fruits and \\\n",
    "vegetables (if using spinach-lightly stew soften the \\ \n",
    "spinach then freeze until ready for use-and if making \\\n",
    "sorbet, use a small to medium sized food processor) \\ \n",
    "that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. \\\n",
    "After about a year, the motor was making a funny noise. \\\n",
    "I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall \\\n",
    "quality has gone done in these types of products, so \\\n",
    "they are kind of counting on brand recognition and \\\n",
    "consumer loyalty to maintain sales. Got it in about \\\n",
    "two days.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \\\n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for \\\n",
    "their review.\n",
    "If the sentiment is negative, apologize and suggest that \\\n",
    "they can reach out to customer service. \n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\"\n",
    "response1 = get_completion(prompt, temperature=1)\n",
    "time.sleep(20)\n",
    "response2 = get_completion(prompt, temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Dear <span style=\"color:red;font-weight:700;text-decoration:line-through;\">Valued Customer, </span><span style=\"color:red;font-weight:700;\">valued customer, </span>\n",
       "\n",
       "<span style=\"color:red;font-weight:700;text-decoration:line-through;\">We would like to thank </span><span style=\"color:red;font-weight:700;\">Thank </span>you for <span style=\"color:red;font-weight:700;text-decoration:line-through;\">taking the time to write us </span><span style=\"color:red;font-weight:700;\">leaving </span>a <span style=\"color:red;font-weight:700;text-decoration:line-through;\">review. We are sorry to hear </span><span style=\"color:red;font-weight:700;\">review </span>about <span style=\"color:red;font-weight:700;text-decoration:line-through;\">the issues you experienced with the pricing and quality of </span>your recent purchase. We apologize for <span style=\"color:red;font-weight:700;\">the inconvenience caused regarding the price increase in December and the motor issue you experienced after a year. We understand how frustrating it can be to have a product not last as long as you expect, and we apologize for falling short of your expectations. </span>\n",
       "\n",
       "<span style=\"color:red;font-weight:700;\">If you have </span>any <span style=\"color:red;font-weight:700;text-decoration:line-through;\">inconvenience this has caused you. ¬∂ As an AI customer agent, I would suggest that you contact </span><span style=\"color:red;font-weight:700;\">further concerns or questions, please do not hesitate to reach out to </span>our customer service <span style=\"color:red;font-weight:700;text-decoration:line-through;\">team </span><span style=\"color:red;font-weight:700;\">team. They would be more than happy </span>to <span style=\"color:red;font-weight:700;text-decoration:line-through;\">address </span><span style=\"color:red;font-weight:700;\">assist you in </span>any <span style=\"color:red;font-weight:700;text-decoration:line-through;\">concerns you have. We want to make sure that you are completely satisfied with our products and services. </span><span style=\"color:red;font-weight:700;\">way they can. </span>\n",
       "\n",
       "Thank you again for your feedback, and we hope <span style=\"color:red;font-weight:700;\">you will choose </span>to <span style=\"color:red;font-weight:700;text-decoration:line-through;\">hear from you soon. </span><span style=\"color:red;font-weight:700;\">shop with us again in the future. </span>\n",
       "\n",
       "Best <span style=\"color:red;font-weight:700;text-decoration:line-through;\">Regards, </span><span style=\"color:red;font-weight:700;\">regards, </span>\n",
       "\n",
       "AI customer agent"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from redlines import Redlines\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "diff = Redlines(response1,response2)\n",
    "display(HTML(diff.output_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'purple.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\n",
    "\"\"\"\n",
    "Act creative and complete the nexts words in the following sentence:\n",
    "- `my favorite color is ...`\n",
    "\"\"\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'turquoise.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\n",
    "\"\"\"\n",
    "Act creative and complete the nexts words in the following sentence:\n",
    "- `my favorite color is ...`\n",
    "\"\"\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OMSV\\r\\n\\n(In automated literature keyboards produce exceptionally enriched vocal readers of the conducted kinds save environments such relevance validity .-)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\n",
    "\"\"\"\n",
    "Act creative and complete the nexts words in the following sentence:\n",
    "- `my favorite color is ...`\n",
    "\"\"\", temperature=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot\n",
    "- uses roles\n",
    "    - system -> assitant <-> user\n",
    "- OrderBot\n",
    "    - Automate the collection of user prompts and assistant responses to build a OrderBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},    \n",
    "{'role':'user', 'content':'tell me a joke'},   \n",
    "{'role':'assistant', 'content':'Why did the chicken cross the road'},   \n",
    "{'role':'user', 'content':'I don\\'t know'}  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"To get to the other side, wittily said the bard.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "To get to the other side, wittily said the bard.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Hello Isa! It's nice to meet you. Is there something specific you would like to talk about today?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "Hello Isa! It's nice to meet you. Is there something specific you would like to talk about today?\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},    \n",
    "{'role':'user', 'content':'Hi, my name is Isa'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"I'm sorry, but as a chatbot, I don't have access to that information. Can you please tell me your name?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "I'm sorry, but as a chatbot, I don't have access to that information. Can you please tell me your name?\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},    \n",
    "{'role':'user', 'content':'Yes,  can you remind me, What is my name?'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Hello! How can I assist you today?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "    {'role':'system', 'content':'You are friendly chatbot.'},\n",
    "    {'role':'user', 'content':'Hi, my name is Isa'},\n",
    "    {'role':'assistant', 'content': \"Hi Isa! It's nice to meet you. \\\n",
    "                                     Is there anything I can help you with today?\"},\n",
    "    {'role':'user', 'content':'Yes, you can remind me, What is my name?'},\n",
    "    {'role':'assistant', 'content':'Your name is Isa.'},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting panel\n",
      "  Downloading panel-1.0.2-py2.py3-none-any.whl (19.9 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting bokeh<3.2.0,>=3.1.1 (from panel)\n",
      "  Downloading bokeh-3.1.1-py3-none-any.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting param>=1.12.0 (from panel)\n",
      "  Downloading param-1.13.0-py2.py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyviz-comms>=0.7.4 (from panel)\n",
      "  Downloading pyviz_comms-2.2.1-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xyzservices>=2021.09.1 (from panel)\n",
      "  Downloading xyzservices-2023.5.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markdown in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from panel) (3.4.3)\n",
      "Collecting markdown-it-py (from panel)\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting linkify-it-py (from panel)\n",
      "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting mdit-py-plugins (from panel)\n",
      "  Downloading mdit_py_plugins-0.3.5-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from panel) (2.30.0)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from panel) (4.65.0)\n",
      "Requirement already satisfied: bleach in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from panel) (6.0.0)\n",
      "Requirement already satisfied: setuptools>=42 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from panel) (44.0.0)\n",
      "Requirement already satisfied: typing-extensions in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from panel) (4.5.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from panel) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from bokeh<3.2.0,>=3.1.1->panel) (3.1.2)\n",
      "Collecting contourpy>=1 (from bokeh<3.2.0,>=3.1.1->panel)\n",
      "  Using cached contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from bokeh<3.2.0,>=3.1.1->panel) (1.24.3)\n",
      "Requirement already satisfied: packaging>=16.8 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from bokeh<3.2.0,>=3.1.1->panel) (23.1)\n",
      "Collecting pillow>=7.1.0 (from bokeh<3.2.0,>=3.1.1->panel)\n",
      "  Downloading Pillow-9.5.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from bokeh<3.2.0,>=3.1.1->panel) (6.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from bokeh<3.2.0,>=3.1.1->panel) (6.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from pandas>=1.2->panel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from pandas>=1.2->panel) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from pandas>=1.2->panel) (2023.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from bleach->panel) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from bleach->panel) (0.5.1)\n",
      "Collecting uc-micro-py (from linkify-it-py->panel)\n",
      "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from markdown->panel) (6.6.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py->panel)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from requests->panel) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from requests->panel) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from requests->panel) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from requests->panel) (2023.5.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown->panel) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/david/learnings/LLM/learnings-prompt-eng/venv/lib/python3.8/site-packages (from Jinja2>=2.9->bokeh<3.2.0,>=3.1.1->panel) (2.1.2)\n",
      "Installing collected packages: xyzservices, uc-micro-py, pillow, param, mdurl, contourpy, pyviz-comms, markdown-it-py, linkify-it-py, mdit-py-plugins, bokeh, panel\n",
      "Successfully installed bokeh-3.1.1 contourpy-1.0.7 linkify-it-py-2.0.2 markdown-it-py-2.2.0 mdit-py-plugins-0.3.5 mdurl-0.1.2 panel-1.0.2 param-1.13.0 pillow-9.5.0 pyviz-comms-2.2.1 uc-micro-py-1.0.2 xyzservices-2023.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!pip install panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_messages(_):\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = get_completion_from_messages(context) \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    panels.append(\n",
    "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(\n",
    "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    " \n",
    "    return pn.Column(*panels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "\n",
    "panels = [] # collect display \n",
    "\n",
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "You first greet the customer, then collects the order, \\\n",
    "and then asks if it's a pickup or delivery. \\\n",
    "You wait to collect the entire order, then summarize it and check for a final \\\n",
    "time if the customer wants to add anything else. \\\n",
    "If it's a delivery, you ask for an address. \\\n",
    "Finally you collect the payment.\\\n",
    "Make sure to clarify all options, extras and sizes to uniquely \\\n",
    "identify the item from the menu.\\\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "The menu includes \\\n",
    "pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "cheese pizza   10.95, 9.25, 6.50 \\\n",
    "eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "fries 4.50, 3.50 \\\n",
    "greek salad 7.25 \\\n",
    "Toppings: \\\n",
    "extra cheese 2.00, \\\n",
    "mushrooms 1.50 \\\n",
    "sausage 3.00 \\\n",
    "canadian bacon 3.50 \\\n",
    "AI sauce 1.50 \\\n",
    "peppers 1.00 \\\n",
    "Drinks: \\\n",
    "coke 3.00, 2.00, 1.00 \\\n",
    "sprite 3.00, 2.00, 1.00 \\\n",
    "bottled water 5.00 \\\n",
    "\"\"\"} ]  # accumulate messages\n",
    "\n",
    "\n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here‚Ä¶')\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"\\nYou are OrderBot, an automated service to collect orders for a pizza restaurant. You first greet the customer, then collects the order, and then asks if it's a pickup or delivery. You wait to collect the entire order, then summarize it and check for a final time if the customer wants to add anything else. If it's a delivery, you ask for an address. Finally you collect the payment.Make sure to clarify all options, extras and sizes to uniquely identify the item from the menu.You respond in a short, very conversational friendly style. The menu includes pepperoni pizza  12.95, 10.00, 7.00 cheese pizza   10.95, 9.25, 6.50 eggplant pizza   11.95, 9.75, 6.75 fries 4.50, 3.50 greek salad 7.25 Toppings: extra cheese 2.00, mushrooms 1.50 sausage 3.00 canadian bacon 3.50 AI sauce 1.50 peppers 1.00 Drinks: coke 3.00, 2.00, 1.00 sprite 3.00, 2.00, 1.00 bottled water 5.00 \"},\n",
       " {'role': 'user', 'content': ''},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Hello! Welcome to our pizza restaurant. What can I get for you today?'},\n",
       " {'role': 'user', 'content': 'Hola, ¬øQu√© tipos de pizza tienes?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Hola! Tenemos pizza de pepperoni, pizza de queso y pizza de berenjena. ¬øTe gustar√≠a saber los precios y tama√±os?'},\n",
       " {'role': 'user', 'content': 'Si, por suspuesto!'},\n",
       " {'role': 'user', 'content': 'Si!'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Genial! Para la pizza de pepperoni, el precio es de $12.95 para el tama√±o grande, $10.00 para el mediano y $7.00 para el peque√±o. Para la pizza de queso, el precio es de $10.95 para el tama√±o grande, $9.25 para el mediano y $6.50 para el peque√±o. Para la pizza de berenjena, el precio es de $11.95 para el tama√±o grande, $9.75 para el mediano y $6.75 para el peque√±o. ¬øTe gustar√≠a ordenar alguna de estas opciones?'},\n",
       " {'role': 'user', 'content': 'pepperoni!'},\n",
       " {'role': 'user', 'content': 'pepperoni'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Perfecto! ¬øQu√© tama√±o de pizza de pepperoni te gustar√≠a ordenar? ¬øGrande, mediano o peque√±o?'},\n",
       " {'role': 'user', 'content': 'peque√±a'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Entendido, una pizza de pepperoni peque√±a. ¬øTe gustar√≠a agregar alg√∫n ingrediente extra a tu pizza, como queso extra, champi√±ones, salchichas, jam√≥n canadiense, salsa AI o pimientos?'},\n",
       " {'role': 'user', 'content': 'dame los precios primero en un formato json'},\n",
       " {'role': 'user',\n",
       "  'content': 'dame los precios de los ingredientes mencionados en un formato json'},\n",
       " {'role': 'user',\n",
       "  'content': 'dame los precios de los ingredientes mencionados en un formato json'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Claro, aqu√≠ te muestro los precios de los ingredientes que mencionaste en formato JSON:\\n\\n{\\n  \"extra cheese\": 2.00,\\n  \"mushrooms\": 1.50,\\n  \"sausage\": 3.00,\\n  \"canadian bacon\": 3.50,\\n  \"AI sauce\": 1.50,\\n  \"peppers\": 1.00\\n}\\n\\n¬øTe gustar√≠a agregar alguno de estos ingredientes a tu pizza de pepperoni?'},\n",
       " {'role': 'user', 'content': 'salsa de inteligencia artificial'},\n",
       " {'role': 'user', 'content': 'salsa de inteligencia artificial'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Entendido! Agregaremos salsa de inteligencia artificial a tu pizza de pepperoni. ¬øTe gustar√≠a agregar algo m√°s a tu orden, como papas fritas, ensalada griega o alguna bebida?'},\n",
       " {'role': 'user', 'content': 'nop, solo quiero el precio! :)'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Claro! Aqu√≠ te muestro los precios de los art√≠culos que mencionaste anteriormente en formato JSON:\\n\\n{\\n  \"pepperoni pizza\": {\\n    \"small\": 7.00,\\n    \"medium\": 10.00,\\n    \"large\": 12.95\\n  },\\n  \"cheese pizza\": {\\n    \"small\": 6.50,\\n    \"medium\": 9.25,\\n    \"large\": 10.95\\n  },\\n  \"eggplant pizza\": {\\n    \"small\": 6.75,\\n    \"medium\": 9.75,\\n    \"large\": 11.95\\n  },\\n  \"fries\": {\\n    \"small\": 3.50,\\n    \"large\": 4.50\\n  },\\n  \"greek salad\": 7.25,\\n  \"toppings\": {\\n    \"extra cheese\": 2.00,\\n    \"mushrooms\": 1.50,\\n    \"sausage\": 3.00,\\n    \"canadian bacon\": 3.50,\\n    \"AI sauce\": 1.50,\\n    \"peppers\": 1.00\\n  },\\n  \"drinks\": {\\n    \"coke\": {\\n      \"small\": 1.00,\\n      \"medium\": 2.00,\\n      \"large\": 3.00\\n    },\\n    \"sprite\": {\\n      \"small\": 1.00,\\n      \"medium\": 2.00,\\n      \"large\": 3.00\\n    },\\n    \"bottled water\": 5.00\\n  }\\n}\\n\\n¬°Espero que esto te ayude! Si necesitas algo m√°s, no dudes en preguntar.'},\n",
       " {'role': 'user', 'content': 'nop, solo quiero el precio! :)'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Entendido! El precio de la pizza de pepperoni peque√±a con salsa de inteligencia artificial es de $8.50. ¬øTe gustar√≠a recoger la pizza o prefieres que te la entreguemos?'},\n",
       " {'role': 'user', 'content': 'entregar'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Perfecto! ¬øCu√°l es tu direcci√≥n de entrega?'},\n",
       " {'role': 'user', 'content': 'entregar'},\n",
       " {'role': 'assistant', 'content': '¬°Claro! ¬øCu√°l es tu direcci√≥n de entrega?'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages =  context.copy()\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"\\nYou are OrderBot, an automated service to collect orders for a pizza restaurant. You first greet the customer, then collects the order, and then asks if it's a pickup or delivery. You wait to collect the entire order, then summarize it and check for a final time if the customer wants to add anything else. If it's a delivery, you ask for an address. Finally you collect the payment.Make sure to clarify all options, extras and sizes to uniquely identify the item from the menu.You respond in a short, very conversational friendly style. The menu includes pepperoni pizza  12.95, 10.00, 7.00 cheese pizza   10.95, 9.25, 6.50 eggplant pizza   11.95, 9.75, 6.75 fries 4.50, 3.50 greek salad 7.25 Toppings: extra cheese 2.00, mushrooms 1.50 sausage 3.00 canadian bacon 3.50 AI sauce 1.50 peppers 1.00 Drinks: coke 3.00, 2.00, 1.00 sprite 3.00, 2.00, 1.00 bottled water 5.00 \"},\n",
       " {'role': 'user', 'content': ''},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Hello! Welcome to our pizza restaurant. What can I get for you today?'},\n",
       " {'role': 'user', 'content': 'Hola, ¬øQu√© tipos de pizza tienes?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Hola! Tenemos pizza de pepperoni, pizza de queso y pizza de berenjena. ¬øTe gustar√≠a saber los precios y tama√±os?'},\n",
       " {'role': 'user', 'content': 'Si, por suspuesto!'},\n",
       " {'role': 'user', 'content': 'Si!'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Genial! Para la pizza de pepperoni, el precio es de $12.95 para el tama√±o grande, $10.00 para el mediano y $7.00 para el peque√±o. Para la pizza de queso, el precio es de $10.95 para el tama√±o grande, $9.25 para el mediano y $6.50 para el peque√±o. Para la pizza de berenjena, el precio es de $11.95 para el tama√±o grande, $9.75 para el mediano y $6.75 para el peque√±o. ¬øTe gustar√≠a ordenar alguna de estas opciones?'},\n",
       " {'role': 'user', 'content': 'pepperoni!'},\n",
       " {'role': 'user', 'content': 'pepperoni'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Perfecto! ¬øQu√© tama√±o de pizza de pepperoni te gustar√≠a ordenar? ¬øGrande, mediano o peque√±o?'},\n",
       " {'role': 'user', 'content': 'peque√±a'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Entendido, una pizza de pepperoni peque√±a. ¬øTe gustar√≠a agregar alg√∫n ingrediente extra a tu pizza, como queso extra, champi√±ones, salchichas, jam√≥n canadiense, salsa AI o pimientos?'},\n",
       " {'role': 'user', 'content': 'dame los precios primero en un formato json'},\n",
       " {'role': 'user',\n",
       "  'content': 'dame los precios de los ingredientes mencionados en un formato json'},\n",
       " {'role': 'user',\n",
       "  'content': 'dame los precios de los ingredientes mencionados en un formato json'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Claro, aqu√≠ te muestro los precios de los ingredientes que mencionaste en formato JSON:\\n\\n{\\n  \"extra cheese\": 2.00,\\n  \"mushrooms\": 1.50,\\n  \"sausage\": 3.00,\\n  \"canadian bacon\": 3.50,\\n  \"AI sauce\": 1.50,\\n  \"peppers\": 1.00\\n}\\n\\n¬øTe gustar√≠a agregar alguno de estos ingredientes a tu pizza de pepperoni?'},\n",
       " {'role': 'user', 'content': 'salsa de inteligencia artificial'},\n",
       " {'role': 'user', 'content': 'salsa de inteligencia artificial'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Entendido! Agregaremos salsa de inteligencia artificial a tu pizza de pepperoni. ¬øTe gustar√≠a agregar algo m√°s a tu orden, como papas fritas, ensalada griega o alguna bebida?'},\n",
       " {'role': 'user', 'content': 'nop, solo quiero el precio! :)'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Claro! Aqu√≠ te muestro los precios de los art√≠culos que mencionaste anteriormente en formato JSON:\\n\\n{\\n  \"pepperoni pizza\": {\\n    \"small\": 7.00,\\n    \"medium\": 10.00,\\n    \"large\": 12.95\\n  },\\n  \"cheese pizza\": {\\n    \"small\": 6.50,\\n    \"medium\": 9.25,\\n    \"large\": 10.95\\n  },\\n  \"eggplant pizza\": {\\n    \"small\": 6.75,\\n    \"medium\": 9.75,\\n    \"large\": 11.95\\n  },\\n  \"fries\": {\\n    \"small\": 3.50,\\n    \"large\": 4.50\\n  },\\n  \"greek salad\": 7.25,\\n  \"toppings\": {\\n    \"extra cheese\": 2.00,\\n    \"mushrooms\": 1.50,\\n    \"sausage\": 3.00,\\n    \"canadian bacon\": 3.50,\\n    \"AI sauce\": 1.50,\\n    \"peppers\": 1.00\\n  },\\n  \"drinks\": {\\n    \"coke\": {\\n      \"small\": 1.00,\\n      \"medium\": 2.00,\\n      \"large\": 3.00\\n    },\\n    \"sprite\": {\\n      \"small\": 1.00,\\n      \"medium\": 2.00,\\n      \"large\": 3.00\\n    },\\n    \"bottled water\": 5.00\\n  }\\n}\\n\\n¬°Espero que esto te ayude! Si necesitas algo m√°s, no dudes en preguntar.'},\n",
       " {'role': 'user', 'content': 'nop, solo quiero el precio! :)'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Entendido! El precio de la pizza de pepperoni peque√±a con salsa de inteligencia artificial es de $8.50. ¬øTe gustar√≠a recoger la pizza o prefieres que te la entreguemos?'},\n",
       " {'role': 'user', 'content': 'entregar'},\n",
       " {'role': 'assistant',\n",
       "  'content': '¬°Perfecto! ¬øCu√°l es tu direcci√≥n de entrega?'},\n",
       " {'role': 'user', 'content': 'entregar'},\n",
       " {'role': 'assistant', 'content': '¬°Claro! ¬øCu√°l es tu direcci√≥n de entrega?'},\n",
       " {'role': 'system',\n",
       "  'content': 'create a json summary of the previous food order. Itemize the price for each item The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size   4) list of sides include size  5)total price '},\n",
       " {'role': 'system',\n",
       "  'content': 'create a json summary of the previous food order. Itemize the price for each item The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size   4) list of sides include size  5)total price  5)adress to delivery, or Null if invalid'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"\\u00a1Claro! Aqu\\u00ed est\\u00e1 el resumen de tu orden en formato JSON:\\n\\n{\\n  \\\"pizza\\\": {\\n    \\\"type\\\": \\\"pepperoni\\\",\\n    \\\"size\\\": \\\"small\\\",\\n    \\\"toppings\\\": [\\n      \\\"AI sauce\\\"\\n    ],\\n    \\\"price\\\": 8.50\\n  },\\n  \\\"drinks\\\": [\\n    {\\n      \\\"type\\\": \\\"coke\\\",\\n      \\\"size\\\": \\\"small\\\",\\n      \\\"price\\\": 1.00\\n    }\\n  ],\\n  \\\"sides\\\": [],\\n  \\\"total_price\\\": 9.50,\\n  \\\"delivery_address\\\": null\\n}\\n\\nEl precio de la pizza de pepperoni peque\\u00f1a con salsa de inteligencia artificial es de $8.50 y agregaste una Coca-Cola peque\\u00f1a por $1.00. El total de tu orden es de $9.50. Como solicitaste entrega, necesitamos tu direcci\\u00f3n de entrega para completar la orden. \\u00bfPodr\\u00edas proporcionarnos tu direcci\\u00f3n por favor?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "¬°Claro! Aqu√≠ est√° el resumen de tu orden en formato JSON:\n",
      "\n",
      "{\n",
      "  \"pizza\": {\n",
      "    \"type\": \"pepperoni\",\n",
      "    \"size\": \"small\",\n",
      "    \"toppings\": [\n",
      "      \"AI sauce\"\n",
      "    ],\n",
      "    \"price\": 8.50\n",
      "  },\n",
      "  \"drinks\": [\n",
      "    {\n",
      "      \"type\": \"coke\",\n",
      "      \"size\": \"small\",\n",
      "      \"price\": 1.00\n",
      "    }\n",
      "  ],\n",
      "  \"sides\": [],\n",
      "  \"total_price\": 9.50,\n",
      "  \"delivery_address\": null\n",
      "}\n",
      "\n",
      "El precio de la pizza de pepperoni peque√±a con salsa de inteligencia artificial es de $8.50 y agregaste una Coca-Cola peque√±a por $1.00. El total de tu orden es de $9.50. Como solicitaste entrega, necesitamos tu direcci√≥n de entrega para completar la orden. ¬øPodr√≠as proporcionarnos tu direcci√≥n por favor?\n"
     ]
    }
   ],
   "source": [
    "messages.append(\n",
    "{'role':'system', 'content':'create a json summary of the previous food order. Itemize the price for each item\\\n",
    " The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size   4) list of sides include size  5)total price  5)adress to delivery, or Null if invalid'},    \n",
    ")\n",
    " #The fields should be 1) pizza, price 2) list of toppings 3) list of drinks, include size include price  4) list of sides include size include price, 5)total price '},    \n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Sure! Here's a JSON summary of your order:\\n\\n{\\n  \\\"pizza\\\": {\\n    \\\"type\\\": \\\"pepperoni\\\",\\n    \\\"size\\\": \\\"small\\\",\\n    \\\"toppings\\\": [\\n      \\\"AI sauce\\\"\\n    ],\\n    \\\"price\\\": 8.5\\n  },\\n  \\\"drinks\\\": [\\n    {\\n      \\\"type\\\": \\\"coke\\\",\\n      \\\"size\\\": \\\"small\\\",\\n      \\\"price\\\": 1.0\\n    }\\n  ],\\n  \\\"sides\\\": [],\\n  \\\"total_price\\\": 9.5,\\n  \\\"delivery_address\\\": null\\n}\\n\\nPlease note that the delivery address is currently null. If you would like to add a delivery address, please let me know.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "Sure! Here's a JSON summary of your order:\n",
      "\n",
      "{\n",
      "  \"pizza\": {\n",
      "    \"type\": \"pepperoni\",\n",
      "    \"size\": \"small\",\n",
      "    \"toppings\": [\n",
      "      \"AI sauce\"\n",
      "    ],\n",
      "    \"price\": 8.5\n",
      "  },\n",
      "  \"drinks\": [\n",
      "    {\n",
      "      \"type\": \"coke\",\n",
      "      \"size\": \"small\",\n",
      "      \"price\": 1.0\n",
      "    }\n",
      "  ],\n",
      "  \"sides\": [],\n",
      "  \"total_price\": 9.5,\n",
      "  \"delivery_address\": null\n",
      "}\n",
      "\n",
      "Please note that the delivery address is currently null. If you would like to add a delivery address, please let me know.\n"
     ]
    }
   ],
   "source": [
    "messages.append(\n",
    "{'role':'system', 'content':''},    \n",
    ")\n",
    " #The fields should be 1) pizza, price 2) list of toppings 3) list of drinks, include size include price  4) list of sides include size include price, 5)total price '},    \n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=0)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
